@article{agarwala2004keyframe,
  title={Keyframe-based tracking for rotoscoping and animation},
  author={Agarwala, Aseem and Hertzmann, Aaron and Salesin, David H and Seitz, Steven M},
  journal={ACM Transactions on Graphics (ToG)},
  volume={23},
  number={3},
  pages={584--591},
  year={2004},
  publisher={ACM}
}

@inproceedings{VNect_SIGGRAPH2017,
  author = {Mehta, Dushyant and Sridhar, Srinath and Sotnychenko, Oleksandr and Rhodin, Helge and Shafiei, Mohammad and Seidel, Hans-Peter and Xu, Weipeng and Casas, Dan and Theobalt, Christian},
  title = {VNect: Real-time 3D Human Pose Estimation with a Single RGB Camera},
  journal = {ACM Transactions on Graphics},
  url = {http://gvv.mpi-inf.mpg.de/projects/VNect/},
  numpages = {14},
  volume={36},
  number={4},
  month = July,
  year = {2017}
  doi={10.1145/3072959.3073596}
}

  
@Inbook{Baak2013,
author="Baak, Andreas
and M{\"u}ller, Meinard
and Bharaj, Gaurav
and Seidel, Hans-Peter
and Theobalt, Christian",
editor="Fossati, Andrea
and Gall, Juergen
and Grabner, Helmut
and Ren, Xiaofeng
and Konolige, Kurt",
title="A Data-Driven Approach for Real-Time Full Body Pose Reconstruction from a Depth Camera",
bookTitle="Consumer Depth Cameras for Computer Vision: Research Topics and Applications",
year="2013",
publisher="Springer London",
address="London",
pages="71--98",
abstract="The 3D reconstruction of complex human motions from 2D color images is a challenging and sometimes intractable problem. The pose estimation problem becomes more feasible when using streams of 2.5D monocular depth images as provided by a depth camera. However, due to low resolution of and challenging noise characteristics in depth camera images as well as self-occlusions in the movements, the pose estimation task is still far from being simple. Furthermore, in real-time scenarios, the reconstruction task becomes even more challenging since global optimization strategies are prohibitive. To facilitate tracking of full-body human motions from a single depth-image stream, we introduce a data-driven hybrid strategy that combines local pose optimization with global retrieval techniques. Here, the final pose estimate at each frame is determined from the tracked and retrieved pose hypotheses which are fused using a fast selection scheme. Our algorithm reconstructs complex full-body poses in real time and effectively prevents temporal drifting, thus making it suitable for various real-time interaction scenarios.",
isbn="978-1-4471-4640-7",
doi="10.1007/978-1-4471-4640-7_5",
url="https://doi.org/10.1007/978-1-4471-4640-7_5"
}

@inproceedings{panin2006efficient,
  title={An efficient and robust real-time contour tracking system},
  author={Panin, Giorgio and Ladikos, Alexander and Knoll, Alois},
  booktitle={Computer Vision Systems, 2006 ICVS'06. IEEE International Conference on},
  pages={44--44},
  year={2006},
  organization={IEEE}
}

@article{buys2014adaptable,
  title={An adaptable system for RGB-D based human body detection and pose estimation},
  author={Buys, Koen and Cagniart, Cedric and Baksheev, Anatoly and De Laet, Tinne and De Schutter, Joris and Pantofaru, Caroline},
  journal={Journal of visual communication and image representation},
  volume={25},
  number={1},
  pages={39--52},
  year={2014},
  publisher={Elsevier}
}

@inproceedings{cao2017realtime,
  author = {Zhe Cao and Tomas Simon and Shih-En Wei and Yaser Sheikh},
  booktitle = {CVPR},
  title = {Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},
  year = {2017}
  }
  
@inproceedings{wei2016cpm,
  author = {Shih-En Wei and Varun Ramakrishna and Takeo Kanade and Yaser Sheikh},
  booktitle = {CVPR},
  title = {Convolutional pose machines},
  year = {2016}
  }

@article{Comaniciu2000,
abstract = {A new method for real time tracking of non-rigid objects seen from a moving camera is proposed. The central computational module is based on the mean shift iterations and finds the most probable target position in the current frame. The dissimilarity between the target model (its color distribution) and the target candidates is expressed by a metric derived from the Bhattacharyya coefficient. The theoretical analysis of the approach shows that it relates to the Bayesian framework while providing a practical, fast and efficient solution. The capability of the tracker to handle in real time partial occlusions, significant clutter, and target scale variations, is demonstrated for several image sequences},
author = {Comaniciu, D and Ramesh, V and Meer, P},
doi = {10.1109/CVPR.2000.854761},
file = {:home/ernest/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Comaniciu, Ramesh, Meer - 2000 - Real-time tracking of non-rigid objects using mean shift.pdf:pdf},
isbn = {0-7695-0662-3},
issn = {01628828},
journal = {IEEE Conference on Computer Vision and Pattern Recognition},
keywords = {Bayes methods,Bayesian framework,Bayesian methods,Bhattacharyya coefficient,Educational institutions,Kernel,Monitoring,Surveillance,Target tracking,Visualization,Yield estimation,clutter,color distribution,computational complexity,computational module,computer vision,image sequences,iterative methods,mean shift iterations,most probable target position,moving camera,non-rigid object tracking,optical tracking,partial occlusions,real time tracking,real-time systems,target candidate,target model,target scale variations},
mendeley-groups = {CV{\_}proj},
number = {7},
pages = {142--149},
title = {{Real-time tracking of non-rigid objects using mean shift}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=854761},
volume = {2},
year = {2000}
}


@Inbook{Loper2014,
author="Loper, Matthew M.
and Black, Michael J.",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="OpenDR: An Approximate Differentiable Renderer",
bookTitle="Computer Vision -- ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part VII",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="154--169",
abstract="Inverse graphics attempts to take sensor data and infer 3D geometry, illumination, materials, and motions such that a graphics renderer could realistically reproduce the observed scene. Renderers, however, are designed to solve the forward process of image synthesis. To go in the other direction, we propose an approximate differentiable renderer (DR) that explicitly models the relationship between changes in model parameters and image observations. We describe a publicly available OpenDR framework that makes it easy to express a forward graphics model and then automatically obtain derivatives with respect to the model parameters and to optimize over them. Built on a new auto-differentiation package and OpenGL, OpenDR provides a local optimization method that can be incorporated into probabilistic programming frameworks. We demonstrate the power and simplicity of programming with OpenDR by using it to solve the problem of estimating human body shape from Kinect depth and RGB data.",
isbn="978-3-319-10584-0",
doi="10.1007/978-3-319-10584-0_11",
url="https://doi.org/10.1007/978-3-319-10584-0_11"
}
@article{twist,
author = {Bregler, C and Malik, Jitendra},
year = {1998},
month = {07},
pages = {8 - 15},
title = {Tracking people with twists and exponential maps},
isbn = {0-8186-8497-6},
booktitle = {Proceedings / CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition. IEEE Computer Society Conference on Computer Vision and Pattern Recognition}
}

@INPROCEEDINGS{7299005, 
author={A. Elhayek and E. de Aguiar and A. Jain and J. Tompson and L. Pishchulin and M. Andriluka and C. Bregler and B. Schiele and C. Theobalt}, 
booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
title={Efficient ConvNet-based marker-less motion capture in general scenes with a low number of cameras}, 
year={2015}, 
volume={}, 
number={}, 
pages={3810-3818}, 
keywords={image motion analysis;optimisation;pose estimation;tracking;ConvNet detection;ConvNet-based marker-less motion capture;analytic derivatives;appearance-based model-to-image similarity term;articulated skeleton motion;cameras;combined pose optimization energy;convolutional networks;discriminative image-based joint detection method;discriminative part-based pose detection method;iterative local optimization;kinematic skeleton model;model-based generative motion tracking algorithm;pose estimation energy;pose posterior;temporal stability;unary potentials;weighted sampling;Cameras;Computational modeling;Joints;Optimization;Three-dimensional displays;Tracking}, 
doi={10.1109/CVPR.2015.7299005}, 
ISSN={1063-6919}, 
month={June},}


@Article{Rosales2006,
author="Rosales, R{\'O}Mer
and Sclaroff, Stan",
title="Combining Generative and Discriminative Models in a Framework for Articulated Pose Estimation",
journal="International Journal of Computer Vision",
year="2006",
month="May",
day="01",
volume="67",
number="3",
pages="251--276",
abstract="We develop a method for the estimation of articulated pose, such as that of the human body or the human hand, from a single (monocular) image. Pose estimation is formulated as a statistical inference problem, where the goal is to find a posterior probability distribution over poses as well as a maximum a posteriori (MAP) estimate. The method combines two modeling approaches, one discriminative and the other generative. The discriminative model consists of a set of mapping functions that are constructed automatically from a labeled training set of body poses and their respective image features. The discriminative formulation allows for modeling ambiguous, one-to-many mappings (through the use of multi-modal distributions) that may yield multiple valid articulated pose hypotheses from a single image. The generative model is defined in terms of a computer graphics rendering of poses. While the generative model offers an accurate way to relate observed (image features) and hidden (body pose) random variables, it is difficult to use it directly in pose estimation, since inference is computationally intractable. In contrast, inference with the discriminative model is tractable, but considerably less accurate for the problem of interest. A combined discriminative/generative formulation is derived that leverages the complimentary strengths of both models in a principled framework for articulated pose inference. Two efficient MAP pose estimation algorithms are derived from this formulation; the first is deterministic and the second non-deterministic. Performance of the framework is quantitatively evaluated in estimating articulated pose of both the human hand and human body.",
issn="1573-1405",
doi="10.1007/s11263-006-5165-4",
url="https://doi.org/10.1007/s11263-006-5165-4"
}


@INPROCEEDINGS{6126356, 
author={A. Baak and M. Müller and G. Bharaj and H. P. Seidel and C. Theobalt}, 
booktitle={2011 International Conference on Computer Vision}, 
title={A data-driven approach for real-time full body pose reconstruction from a depth camera}, 
year={2011}, 
volume={}, 
number={}, 
pages={1092-1099}, 
keywords={cameras;image motion analysis;image reconstruction;object tracking;pose estimation;3D pose estimation;Dijkstra's algorithm;data-driven approach;data-driven hybrid strategy;depth camera;depth data;full-body motion tracking;global pose estimates;global retrieval techniques;local pose estimates;monocular 2.5D depth images;pose features;real-time frame rates;real-time full body pose reconstruction;real-time tracking;self-occlusions;single depth image stream;sparse Hausdorff distance;Cameras;Databases;Estimation;Joints;Optimization;Torso;Tracking}, 
doi={10.1109/ICCV.2011.6126356}, 
ISSN={1550-5499}, 
month={Nov},}

@ARTICLE{7457693, 
author={M. Ye and Y. Shen and C. Du and Z. Pan and R. Yang}, 
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
title={Real-Time Simultaneous Pose and Shape Estimation for Articulated Objects Using a Single Depth Camera}, 
year={2016}, 
volume={38}, 
number={8}, 
pages={1517-1532}, 
keywords={Gaussian processes;cameras;mixture models;pose estimation;probability;GPU;Gaussian mixture model;articulated deformation model;articulated objects;dynamic pose estimation process;exponential-maps-based parametrization;extra calibration procedure;mesh model;middle-range graphics card;personalized shape model;pipeline processing;probabilistic measurement model;real-time simultaneous pose estimation;real-time simultaneous shape estimation;shape adaptation algorithm;single depth camera;sphere-set model;statistical shape model;Adaptation models;Heuristic algorithms;Real-time systems;Sensors;Shape;Generative pose tracking;depth cues;motion;range data;real-time tracking;shape registration;surface fitting}, 
doi={10.1109/TPAMI.2016.2557783}, 
ISSN={0162-8828}, 
month={Aug},}

@article{Dou:2016:FRP:2897824.2925969,
 author = {Dou, Mingsong and Khamis, Sameh and Degtyarev, Yury and Davidson, Philip and Fanello, Sean Ryan and Kowdle, Adarsh and Escolano, Sergio Orts and Rhemann, Christoph and Kim, David and Taylor, Jonathan and Kohli, Pushmeet and Tankovich, Vladimir and Izadi, Shahram},
 title = {Fusion4D: Real-time Performance Capture of Challenging Scenes},
 journal = {ACM Trans. Graph.},
 issue_date = {July 2016},
 volume = {35},
 number = {4},
 month = jul,
 year = {2016},
 issn = {0730-0301},
 pages = {114:1--114:13},
 articleno = {114},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/2897824.2925969},
 doi = {10.1145/2897824.2925969},
 acmid = {2925969},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {4D reconstruction, multi-view, nonrigid, real-time},
} 

@inproceedings{panin2006efficient,
  title={An efficient and robust real-time contour tracking system},
  author={Panin, Giorgio and Ladikos, Alexander and Knoll, Alois},
  booktitle={Computer Vision Systems, 2006 ICVS'06. IEEE International Conference on},
  pages={44--44},
  year={2006},
  organization={IEEE}
}

@INPROCEEDINGS{1640835, 
author={A. Adam and E. Rivlin and I. Shimshoni}, 
booktitle={2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)}, 
title={Robust Fragments-based Tracking using the Integral Histogram}, 
year={2006}, 
volume={1}, 
number={}, 
pages={798-805}, 
keywords={Data mining;Data structures;Histograms;Humans;Robustness;Statistics;Target tracking;Torso;Video sequences;Voting}, 
doi={10.1109/CVPR.2006.256}, 
ISSN={1063-6919}, 
month={June},}


@inbook{Kwon2014,
abstract = {A novel tracking algorithm that can track a highly non-rigid target robustly is proposed using a new bounding box representation called the Double Bounding Box (DBB). In the DBB, a target is described by the combination of the Inner Bounding Box (IBB) and the Outer Bounding Box (OBB). Then our objective of visual tracking is changed to find the IBB and OBB instead of a single bounding box, where the IBB and OBB can be easily obtained by the Dempster-Shafer (DS) theory. If the target is highly non-rigid, any single bounding box cannot include all foreground regions while excluding all background regions. Using the DBB, our method does not directly handle the ambiguous regions, which include both the foreground and background regions. Hence, it can solve the inherent ambiguity of the single bounding box representation and thus can track highly non-rigid targets robustly. Our method finally finds the best state of the target using a new Constrained Markov Chain Monte Carlo (CMCMC)-based sampling method with the constraint that the OBB should include the IBB. Experimental results show that our method tracks non-rigid targets accurately and robustly, and outperforms state-of-the-art methods.},
address = {Cham},
author = {Kwon, Junseok and Roh, Junha and Lee, Kyoung Mu and {Van Gool}, Luc},
booktitle = {Computer Vision -- ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I},
doi = {10.1007/978-3-319-10590-1_25},
editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
isbn = {978-3-319-10590-1},
mendeley-groups = {CV{\_}proj},
pages = {377--392},
publisher = {Springer International Publishing},
title = {{Robust Visual Tracking with Double Bounding Box Model}},
url = {https://doi.org/10.1007/978-3-319-10590-1{\_}25},
year = {2014}
}


@INPROCEEDINGS{1544896, 
author={E. Rosten and T. Drummond}, 
booktitle={Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1}, 
title={Fusing points and lines for high performance tracking}, 
year={2005}, 
volume={2}, 
number={}, 
pages={1508-1515 Vol. 2}, 
keywords={edge detection;feature extraction;image motion analysis;sensor fusion;solid modelling;target tracking;3D model-based tracking;400 Hz;FAST feature detector;edge-based tracking system;feature detection;feature tracking;high performance tracking;online learning;point-based tracking system;prediction errors;sensor systems;Acceleration;Cameras;Computer vision;Detectors;Layout;Performance analysis;Real time systems;Robustness;Sensor systems;Tracking}, 
doi={10.1109/ICCV.2005.104}, 
ISSN={1550-5499}, 
month={Oct},}


@Inbook{Bay2006,
author="Bay, Herbert
and Tuytelaars, Tinne
and Van Gool, Luc",
editor="Leonardis, Ale{\v{s}}
and Bischof, Horst
and Pinz, Axel",
title="SURF: Speeded Up Robust Features",
bookTitle="Computer Vision -- ECCV 2006: 9th European Conference on Computer Vision, Graz, Austria, May 7-13, 2006. Proceedings, Part I",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="404--417",
abstract="In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster.",
isbn="978-3-540-33833-8",
doi="10.1007/11744023_32",
url="https://doi.org/10.1007/11744023_32"
}

