\documentclass[11pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[breaklinks=true,bookmarks=false]{hyperref}
\usepackage{color}
\usepackage{indentfirst}
\usepackage{listings}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}


\lstdefinestyle{mystyle}{
  backgroundcolor=\color{backcolour},
  commentstyle=\color{codegreen},
  keywordstyle=\color{magenta},
  numberstyle=\tiny\color{codegray},
  stringstyle=\color{codepurple},
  basicstyle=\footnotesize,
  breakatwhitespace=false,
  breaklines=true,
  captionpos=b,
  keepspaces=true,
  numbers=left,
  numbersep=5pt,
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  tabsize=2
}
\lstset{style=mystyle}
\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{1}
\begin{document}

%%%%%%%%% TITLE
\title{
Computer Vision Course Project Report\\
Gambody
}

\author{Rong Yuyang, Cai Jianxion, Li Ziyue, Huang Jingyi, Pang Anqi\\
School of Information Science and Technolody\\
ShanghaiTech University\\
{\tt\small \{rongyy, caijx, lizy, huangjy, pangaq\}@shanghaitech.edu.cn}
}

\maketitle

\begin{abstract}

\end{abstract}
\section{Introduction}
    \par We found a popular game called \textit{Hole in the Wall}. In this game one (or two) player(s) are facing a moving wall with a certain shape of hole, the player have to make a specific pose to pass the moving wall or he will be pushed into a water pool behind him. Such a game is interesting but householders can never have the privilege to play in family gatherings or parties since one can hardly find a moving wall nor adequate safety measurements.
        \begin{figure}[h]
            \centering
            \includegraphics[width=0.8\linewidth]{./Pic/HIW_Logo}
            \caption{Game Logo}
        \end{figure}
        \begin{figure}[h]
            \centering
            \includegraphics[width=0.45\linewidth]{./Pic/HIW_RedTeam}
            \includegraphics[width=0.45\linewidth]{./Pic/HIW_BlueTeam}
            \caption{Two players in the game posing to pass the wall.}
        \end{figure}
    \par To fix this, we are going to implement a system based on camera so that every one can play this game.
        In our work, we will be using one single camera to track person. It will also give player a bounding box (moving wall), which is remarked as a mask in the system.
        The mask and player's body part is compared by our system, the return should be a pass (True) or no pass (False). More details about our technical approaches are in Section 3. And the subsection Mask Generation introduces how to generate masks.
    \par In Section 3, we will propose two versions of implementations. In the first version, we apply direct subtraction to get the body part of the player and return a pass if the overlap of body and mask is greater than a threshold. More details are included in the subsection Version One. Since this naive version is parameter-dependent and has low robustness, we implement a more advanced version based on a previous work \textit{Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields}\cite{cao2017realtime}. Specifically, we compare the skeletons of the mask and the player and define a loss function computing the euclidean distance. Likewise, the system returns a pass if the loss is smaller than a threshold. More details about this version are included in the subsection Openpose.
    \par In both versions, we have no need to care about object noise. But there may be circumstances that some passers-by appear resulting in the ambiguity on deciding which is the player. To deal with this kind of noise, we have tried out two solutions. One is called \emph{highest wins} strategy, and the other bases on \emph{trajectory predition}. The efforts on noise cancellation are presented in the subsection Noise.
    \par We also did some experiments to improve the system further. In Section 4, the trials about \emph{weights on skeleton} and \emph{noise cancellation parameters} are introduced in detail respectively.
\section{Related Work}
Our goal is to get 2D or 3D stable skeleton from sigle webcam with out depth channal(using only RGB) in real time. We focus the discussion of related work on approaches of using other camera and not in real time. We will also introduce some real-time skeleton reconstruction with one sigle camera.
  \subsection{Multi View}
  With multi-view setups markerless motion-captue solutions attain high accuracy, and it is also easy to get the depth information from multi-view.Most methods target high quality with offline computation \cite{Loper2014}\cite{twist}.Robustness could be increased with a combination of generative and discriminative estimation \cite{7299005}, even from a single input view \cite{Rosales2006}.
  \subsection{Monocular Depth}
  The depth channel provided by RGB-D sensors has led to robust real-time pose estimation solutions\cite{6126356}\cite{7457693}. Even real-time tracking of templete free reconstruction is now aviliable\cite{Dou:2016:FRP:2897824.2925969}.The depth information overcome forward-backward  ambiguities in monocular camera. Our goal is to use one webcam to achieve 2D or 3D skeleton reconstruct.
  \subsection{Monocular RGB}
  These approach is what we need, one is the real-time  full global 3D skeletal pose of a human in a stable, temporally consistent manner using a single RGB camera method \cite{VNect_SIGGRAPH2017}, but it cost much resource especially when we want to build a game on a poor platform.\\
  Another is the openpose method\cite{cao2017realtime}\cite{wei2016cpm}, they efficiently detect the 2D pose of multiple people in an image. The approach uses a nonparametric representation to learn to associate body parts with individuals in the image. This is also the method we use.

\section{Our Approach}
	\subsection{Mask Generation}
		\par We generate mask by taking a photo of a pose and the background first.
		Then we substract the image to get the binary mask of the pose.
		We also use Openpose to generate a skeleton data and image.
		\begin{figure}[h]
			\centering
			\includegraphics[width=0.45\linewidth]{./Pic/Approach_Mask_back}
			\includegraphics[width=0.45\linewidth]{./Pic/Approach_Mask_pose}
			\caption{Initial images given}
		\end{figure}
		\begin{figure}[h]
			\centering
			\includegraphics[width=0.9\linewidth]{./Pic/Approach_Mask_binary_mask}
			\includegraphics[width=0.9\linewidth]{./Pic/Approach_Mask_skeleton}
			\caption{Mask generated}
		\end{figure}
	\subsection{Version One}
        \par We implemented a first version of system in the early stage of this project. To achieve real-time image processing and displaying, we keep on capturing an image from the camera stream, modifying the image, and showing it on the screen. An infinite loop is kept so. For image processing, the pipeline is shown in Figure 5.
        \par Based on the fact that the background doesn't change during the game time, we capture a background image at the very beginning. Subtracting it from the image having the player, the body part is obtained roughly, which is just the remainder.
        \par However, the subtraction result may have some noise, especially the edges because of the unavoidable camera shake. To eliminate the edge effects, we use a gaussian filter to blur the images before doing subtraction.
        \par Another problem remained is that the body detected may be isolated, particularly the head. So we have to find the two maximum connected components and combine them together to get the complete body part.
        \par Finally, provided with the mask image and the body image, we compare them by computing the normalized correlation ratio. If the maximum value (the best match ratio) is greater than a pre-set threshold, the system returns a pass to the player.
        \begin{figure}[htbp]
			\centering
			\includegraphics[width=0.9\linewidth]{./Pic/flowchart.png}
			\caption{Pipeline for image processing in Version One.}
		\end{figure}
	\subsection{Openpose\cite{cao2017realtime}}
	    \par To generate a skeleton we have to generate confidence map using which we can determine where the joint is.
		Each joint is self-defined, so joint here can be eyes and ears.
		18 joints is defined, which is eyes(2), ears(2), nose(1), chest(1), shoulders(2), elbows(2), wrists(2), waists(2), knees(2) and ankles(2).
		We also have to predict Part Affine Fields, which can be used to generate a cost for each connection.
		\par With joints and connection cost, how to connect joints become a bipartite graph maximum matching problem.
		\par We used the binary executable\cite{cao2017realtime} when testing. We will take the last image and give it to the executable. The executable will generate a json file describing each detected joint for each person.
	    \subsubsection{Json}

	\subsection{Noise}
\section{Experiment}
	\subsection{Weight on Skeleton}
	\subsection{Noise Cancellation Parameter}
\section{Conclusion}


{\small
\bibliographystyle{ieee}
\bibliography{report}
}
\end{document}
